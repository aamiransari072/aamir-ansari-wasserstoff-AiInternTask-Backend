# Chatbot Backend API

A powerful backend API for processing PDFs and answering queries using advanced AI technologies. This system combines document processing, vector storage, and large language models to provide intelligent responses to user queries.

## ğŸ¯ Objective

The Chatbot Backend API is designed to:
- Process and store PDF documents efficiently
- Create vector embeddings for semantic search
- Provide intelligent answers to user queries based on document content
- Support document retrieval and source attribution
- Enable secure file storage and access

## ğŸ—ï¸ Architecture

The system consists of several key components:

### 1. PDF Processing Pipeline
- Handles PDF document ingestion and processing
- Extracts text content from PDFs
- Splits documents into manageable chunks
- Creates vector embeddings using OpenAI's embedding model
- Stores vectors in Pinecone for efficient retrieval
- Manages document metadata in MongoDB
- Stores original files in S3-compatible storage (Cloudflare R2)

### 2. Query Pipeline
- Processes user queries using semantic search
- Retrieves relevant document chunks from Pinecone
- Uses OpenAI's GPT-4 model for generating responses
- Provides source attribution for answers
- Supports document reranking for improved relevance

### 3. API Layer
- FastAPI-based REST API
- CORS-enabled for frontend integration
- Secure file upload and download endpoints
- Health check and monitoring endpoints

## ğŸ”„ Workflow

### PDF Processing Flow

```
User Upload
   â”‚
   â–¼
validate_pdf()
   â”‚
   â–¼
save_pdf_to_temp()
   â”‚
   â–¼
upload_file_to_s3() â”€â–º S3 Bucket
   â”‚
   â–¼
save_metadata_to_mongodb() â”€â–º MongoDB
   â”‚
   â–¼
load_documents_from_pdf()
   â”‚
   â–¼
split_data() â”€â–º Recursive chunks
   â”‚
   â–¼
embed_query() â”€â–º Embeddings
   â”‚
   â–¼
upsert() â”€â–º Pinecone Vector DB
   â”‚
   â–¼
update_document_in_mongodb(processed=True)
   â”‚
   â–¼
Clean up temp file
```

### PDF Processing Decision Flow

```
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Upload    â”‚
         â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
      Validate PDF Format
               â”‚
               â–¼
  Try PyPDFLoader (fails on scanned PDF)
               â”‚
               â–¼
Fallback to UnstructuredPDFLoader (uses OCR)
               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
        â”‚Text Found? â”‚â”€â”€Noâ”€â–º Clean up + Error
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
               â”‚Yes
               â–¼
     Proceed with chunking, embedding, vector storage
```

### Query Processing Flow

```
User Query
   â”‚
   â–¼
Process Query
   â”‚
   â–¼
Retrieve Relevant Documents from Pinecone
   â”‚
   â–¼
Generate Context from Retrieved Documents
   â”‚
   â–¼
Send to OpenAI GPT-4
   â”‚
   â–¼
Generate Response
   â”‚
   â–¼
Prepare Source Information
   â”‚
   â–¼
Return Response with:
   â”œâ”€â–º Answer
   â”œâ”€â–º Source Documents
   â””â”€â–º S3 URLs for Download
```

### Source Document Access
- Each source document is accessible via a secure S3 URL
- URLs are generated using signed requests for security
- Users can download original documents through the `/api/proxy/download` endpoint
- Source attribution includes:
  - Document ID
  - Original filename
  - S3 URL for download
  - Relevance score

## ğŸš€ Getting Started

### Prerequisites

- Python 3.8+
- MongoDB
- Pinecone account
- OpenAI API key
- Cloudflare R2 (or S3-compatible storage)
- Virtual environment (recommended)

### Environment Setup

1. Clone the repository:
```bash
git clone <repository-url>
cd <repository-name>
```

2. Create and activate a virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Create a `.env` file with the following variables:
```env
# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# Pinecone Configuration
PINECONE_API_KEY=your_pinecone_api_key
PINECONE_ENVIRONMENT=your_pinecone_environment
PINECONE_INDEX_NAME=your_index_name

# MongoDB Configuration
MONGODB_URI=your_mongodb_uri
MONGODB_DB_NAME=your_database_name

# S3/R2 Configuration
AWS_ACCESS_KEY_ID=your_access_key
AWS_SECRET_ACCESS_KEY=your_secret_key
S3_BUCKET_NAME=your_bucket_name
ENDPOINT_URL=your_endpoint_url
```

### Running the Application

1. Start the FastAPI server:
```bash
uvicorn app:app --reload
```

2. Access the API documentation:
```
http://localhost:8000/docs
```

### API Endpoints

- `GET /`: Welcome message
- `GET /healthz`: Health check endpoint
- `POST /process-pdfs`: Upload and process PDF documents
- `POST /query`: Submit queries for processing
- `POST /api/proxy/download`: Download processed documents

## ğŸ§ª Testing

The project includes test scripts for both pipelines:

1. Test PDF Processing:
```bash
python src/examples/test_pdf_pipeline.py <path-to-pdf>
```

2. Test Query Pipeline:
```bash
python src/examples/test_query_pipeline.py "your query"
```

## ğŸ“ Author

@aamiransari072

